#### 5.5.5.4. RANSAC & PROSAC

- RANdom SAmple Consensus

即随机采样一致性算法，最早被提出用于解决从一组包含异常点（**out-lier**）和噪声的数据中正确拟合/计算出产生这组数据的**数学模型**或**概率分布中的参数**。而我们要解决的问题正是要将匹配点对中的错配点排除以找到正确的投影变换矩阵，因此恰好可以用RANSAC来解决。在此例中，图像B中的每个像素点都是由A中的像素点经过投影变换后得到的，投影变换矩阵就是我们要找到的数学模型，而两幅图中的特征点，就可以看作是从图像中经过某种特殊的采样得到的。

为了帮助理解，我们先看一个用RANSAC解决线性回归的例子。对于一组有较多立群点的数据（但它们实际上又不是那么离谱，无法通过阈值筛选的方法将其删除），倘若用常规方法如最小二乘可能导致解被外点带偏，迭代方法如梯度下降则容易引起优化过程中的不稳定甚至发散。而从**概率角度**出发的RANSAC则可以较好的解决这个问题（在某些方面有点像BRIEF描述子）。

![](C:\Users\Neo\Desktop\vision_tutorial\Image_base\RANSACexample.png)

<center>左侧是待拟合数据，右侧是RANSAC得到的结果</center>

对于线性回归的例子，数学模型是直线的斜率$k$和截距$b$，确定两个参数至少需要两个方程，作者在论文中特意提到，我们只选择**最少的能够确定模型的样本个数**。RANSAC通过如下方法进行拟合：

1. 数据点中随机选择2个，并由此计算出直线的两个参数
2. 由第一步得到的数学模型，用剩下的点对其进行检验，并通过拟合优度检验（MSE、MAE等，也可以通过启发式的方法设置一个容忍度$\epsilon$并统计和模型相差$\epsilon$以内的点的个数）来评估本次采样的准确性（相当于计算loss）
3. 若拥有最高的拟合程度，则更新模型参数
4. 若未达到精度要求或迭代轮数上限，回到1

实际上我们可以发现RANSAC根本没有在拟合数学模型，而是力图通过不断地“抽奖”，博取采样点都落在真实模型上的可能性，作者真是颇有赌徒心理啊。可就是这样简单的方法，却分外的好用。不过RANSAC未必可以得到最优的效果/正确的模型，从概率上来说，我们需要在迭代轮数和精度之间权衡（如果模型过于复杂，或者你的运气就是有丶背，很可能经过N多轮迭代也得不到正确的结果）

了解了RANSAC的原理，我们只需要把他运用在特征点匹配上就可以了，按照上面的流程，自己对号入座吧！



- PROgressive SAmple Consensus

即渐进采样一致性，相比RANSAC对所有样本点都**一视同仁**不偏不倚的随机采样策略，PROSAC则对“好学生”有偏袒之心。如果我们在迭代之前能够掌握一些有关数据点的质量的信息，那么就可以对那些“成绩好”的学生多多关照一下。以特征点匹配为例，点对的**相似性**（点对的距离）就是度量样本点质量的一个很好的标准。因此PROSAC在处理前还要进行预排序，然后根据某种策略赋予不同排位的样本以不同的采样权重，之后的过程就和前述的四部曲一模一样了。

PROSAC依照的原理就是：**具有更高相似性的数据更可能是内点**，若用根据相似性进行排序的样本进行**半随机采样**（semi-random），得到的效果一定不会比完全随机采样的效果更差（下界）。

> 对于前面举的线性回归例子，怎么样判断一个数据是否更有可能是真实数据呢？聚类、决策树都是很好的方法！不过实际上在一些比较难定量计算相似性的时候，处理会更复杂一些，详见PROSAC的论文：
>
> 笔者认为还可以对PROSAC进行改进，得到D-PROSAC（dynamic，我自己取的名字），即在迭代的过程中，若某次采样的数据拟合出的模型已经比较好但是还没有达到要求（如目标是有90%的点落在邻域内，此次迭代有70%了），那么我们可以增加这一轮采样到的点或此轮迭代出的模型覆盖到的点的权重，让其在之后的采样中变得更重要。这只是一个直观的猜想，概率论学的好的同学可以帮我论证一下这个观点是否成立（笑）。

OpenCV在`ccalib3d`中提供了`cv::findHomography`以寻找两组特征点之间的投影矩阵，通过传递参数来选择RANSAC、PROSAC和最小二乘。
