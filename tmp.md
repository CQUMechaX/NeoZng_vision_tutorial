



## 6.3.测距与深度估计

> 在前面的解算中我们已经知道了装甲板、能量机关等在图像坐标系中的位置，那我们要如何通过相机成像模型中的投影关系把它们还原回世界坐标系中的三维点，得到装甲板相对于相机中心的距离和偏角呢？接下来就会讲解距离测量算法。由于比赛中涉及到的测量和3维重建算法不是很多，并且和相机成像模型有一定的重合，故删去了第五部分的相关内容，统一在第六部分进行介绍。

### 6.3.1. 传统的定点解算方法

- 单目相机的PnP解算方法

  3点、4点，立体几何解算














---



### 6.3.2. 双目视觉和深度相机

- 双目相机



[RM 教程 6 —— 特征点，双目相机与光流 | Harry's Blog (harry-hhj.github.io)](https://harry-hhj.github.io/posts/RM-Tutorial-6-Stereo/#双目视觉)










- 深度相机









---



### 6.3.3. 激光雷达与相机联标












---



### 6.3.4. 深度学习方法

一张depth map很容易让人联想到卷积神经网络生成的feature map，和语义分割任务。而基于卷积神经网络的深度估计方法也已经兴起许久。语义分割是逐像素的分类任务，而深度估计则是逐像素的回归任务，要得到图像上每一个点距离相机光心的距离（再次感慨神经网络真的是万能的）。

双目更适合



数据集较难获取。



更换相机、更换镜头甚至改变焦距，受光线的影响大



速度限制，需要一个单独的网络来解算，不过也可以融合到目标检测网络中于检测头部并行，（是否能共享前面的feature map？怕是不能）



